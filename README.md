# ğŸ“Š PE Intelligence Agent

Conversational AI for Private Equity analysts. Built with **LangChain `create_agent`** + **Groq**.

## How It Works
```
User asks "Tell me about CRED"
  â†’ lookup_entity("CRED")            # Step 1: check dataset
  â†’ âœ… FOUND (FinTech, Mumbai)        # exists in our data
  â†’ Response [Source: Dataset]        # answer from dataset only

User asks "Tell me about Stripe"
  â†’ lookup_entity("Stripe")          # Step 1: check dataset
  â†’ âŒ NOT FOUND                      # not in our data
  â†’ web_search("Stripe funding")     # Step 2: search web
  â†’ Response [Source: External]       # clearly labeled

User asks "Top 10 funded deals?"
  â†’ analyze_dataset(operation="top", column="Amount(in USD)")
  â†’ Response [Source: Dataset]

User asks "Startups with 3+ founders?"
  â†’ analyze_dataset(operation="filter", filters=[{"Founders": {"min_items": 3}}])
  â†’ Response [Source: Dataset]
```

## Architecture
```
agent.py
â”œâ”€â”€ load_data()           â†’ loads CSVs, cleans, deduplicates into DataFrame
â”œâ”€â”€ detect_entity()       â†’ existence check across 4 columns (1 row, minimal output)
â”œâ”€â”€ _apply_filters()      â†’ 10 filter types (contains, exact, range, negation, etc.)
â”œâ”€â”€ analyze_dataset_function() â†’ 12 structured operations (no exec/eval)
â”œâ”€â”€ @tool lookup_entity   â†’ wraps detect_entity for the LLM
â”œâ”€â”€ @tool analyze_dataset â†’ wraps analyze_dataset_function for the LLM
â”œâ”€â”€ @tool web_search      â†’ DuckDuckGo fallback
â”œâ”€â”€ create_agent(llm, tools, system_prompt)
â””â”€â”€ chat() / reset()
```

## Setup
```bash
pip install -r requirements.txt
```

Create a `.env` file:
```
GROQ_API_KEY=your_api_key_here
```

## Run
```bash
# CLI demo
python agent.py

# Interactive chat
python agent.py --interactive

# Web UI
streamlit run app.py
```

## Files
```
pe-intelligence-agent/
â”œâ”€â”€ agent.py            # Data loading, tools, agent, chat
â”œâ”€â”€ app.py              # Streamlit UI (imports from agent.py)
â”œâ”€â”€ data.csv          # Pre-processed dataset (2,119 rows)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                # API key (not committed)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ data/
    â”œâ”€â”€ 2020/
    â”‚   â”œâ”€â”€ Jan_2020.csv
    â”‚   â”œâ”€â”€ Feb_2020.csv
    â”‚   â””â”€â”€ ...
    â””â”€â”€ 2021/
        â”œâ”€â”€ Jan_2021.csv
        â””â”€â”€ ...
```

## Dataset

2,119 startup funding records (2020â€“2021) across 1,659 unique startups. Columns: startup_id,Startup Name, Founding Date, City, Industry/Vertical, Sub-Vertical, Founders, Investors, Amount(in USD), Investment Stage, _country, _continent,_source_month,_source_year.

## Tools

| Tool | Purpose | When |
|---|---|---|
| `lookup_entity` | Check if entity exists in dataset | FIRST, for any named entity |
| `analyze_dataset` | 12 structured operations (top, group, filter, trend, etc.) | Analytics across rows |
| `web_search` | DuckDuckGo search | Only after lookup_entity returns NOT FOUND |

## Filter System

| Type | Example |
|---|---|
| Contains | `{"City": "Bangalore"}` |
| Exact | `{"City": {"exact": "New Delhi"}}` |
| Negation | `{"City": {"not": "Mumbai"}}` |
| OR list | `{"City": ["Bangalore", "Mumbai"]}` |
| Numeric range | `{"Amount(in USD)": {"min": 1000000, "max": 50000000}}` |
| Item count | `{"Founders": {"min_items": 3}}` |
| String length | `{"Startup Name": {"min_len": 4}}` |
| Starts/ends with | `{"Startup Name": {"starts_with": "A"}}` |

## Operations

| Operation | Example Query |
|---|---|
| `top` / `bottom` | "Top 10 funded deals" |
| `group` | "Funding by industry" / "Compare 2020 vs 2021" |
| `filter` | "FinTech startups in Bangalore" |
| `count` | "Deals per investment stage" |
| `sum` | "Total capital deployed" |
| `unique` | "How many unique investors?" |
| `trend` | "Monthly funding trend" |
| `investor_network` | "Most active investors" |
| `landscape` | "Map the FinTech landscape" |
| `crosstab` | "Which cities dominate which sectors?" |
| `stats` | "What % of deals are FinTech?" |
